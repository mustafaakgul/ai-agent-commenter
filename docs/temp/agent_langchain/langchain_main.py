import json
import os
from typing import Dict, List
from langchain.llms import Anthropic
from langchain.chat_models import ChatAnthropic
from langchain.prompts import PromptTemplate, ChatPromptTemplate
from langchain.chains import LLMChain, SequentialChain
from langchain.schema import BaseOutputParser
from langchain.agents import initialize_agent, AgentType, Tool
from langchain.memory import ConversationBufferMemory
from dotenv import load_dotenv


load_dotenv()


class CommentAnalysisParser(BaseOutputParser):
    """Yorum analizi Ã§Ä±ktÄ±sÄ±nÄ± parse eden sÄ±nÄ±f"""

    def parse(self, text: str) -> Dict:
        """LLM Ã§Ä±ktÄ±sÄ±nÄ± dict formatÄ±na Ã§evir"""
        try:
            # Basit parsing - gerÃ§ek projede daha sofistike olabilir
            lines = text.strip().split('\n')
            result = {}

            for line in lines:
                if ':' in line:
                    key, value = line.split(':', 1)
                    result[key.strip().lower()] = value.strip()

            return result
        except Exception as e:
            return {"error": f"Parsing hatasÄ±: {str(e)}"}


class ResponseParser(BaseOutputParser):
    """Cevap Ã§Ä±ktÄ±sÄ±nÄ± parse eden sÄ±nÄ±f"""

    def parse(self, text: str) -> str:
        """LLM Ã§Ä±ktÄ±sÄ±ndan temiz cevap Ã§Ä±kar"""
        # Gereksiz aÃ§Ä±klamalarÄ± temizle
        response = text.strip()
        if response.startswith('"') and response.endswith('"'):
            response = response[1:-1]
        return response


class ECommerceCommentProcessor:
    """Ana iÅŸlem sÄ±nÄ±fÄ± - LangChain chains'lerini yÃ¶netir"""

    def __init__(self):
        # Claude LLM initialize
        self.llm = ChatAnthropic(
            model="claude-3-7-sonnet-20250219",
            anthropic_api_key=os.getenv("ANTHROPIC_API_KEY"),
            temperature=0.3
        )

        self.analysis_parser = CommentAnalysisParser()
        self.response_parser = ResponseParser()

        # Chain'leri oluÅŸtur
        self._create_chains()

    def _create_chains(self):
        """LangChain chain'lerini oluÅŸtur"""

        # 1. ANALYSIS CHAIN - Yorum Analizi
        analysis_prompt = ChatPromptTemplate.from_template("""
        Sen e-ticaret yorumlarÄ±nda uzman bir analistsin. 
        AÅŸaÄŸÄ±daki yorumu analiz et ve ÅŸu formatta Ã§Ä±ktÄ± ver:

        Yorum: {comment}

        Analiz et:
        Sentiment: (Pozitif/Negatif/NÃ¶tr)
        Kategori: (ÃœrÃ¼n Kalitesi/Kargo/Fiyat/Hizmet/Genel)
        Ã–nem: (YÃ¼ksek/Orta/DÃ¼ÅŸÃ¼k)  
        Aciliyet: (Var/Yok)
        Anahtar Kelimeler: (virgÃ¼lle ayÄ±r)
        """)

        self.analysis_chain = LLMChain(
            llm=self.llm,
            prompt=analysis_prompt,
            output_key="analysis_result",
            output_parser=self.analysis_parser
        )

        # 2. RESPONSE GENERATION CHAIN - Cevap Ãœretme
        response_prompt = ChatPromptTemplate.from_template("""
        Sen Trendyol'da satÄ±ÅŸ yapan bir maÄŸazanÄ±n mÃ¼ÅŸteri hizmetleri uzmanÄ±sÄ±n.

        Orijinal Yorum: {comment}
        Analiz Sonucu: {analysis_result}

        Bu yoruma SADECE cevap metnini yaz. BaÅŸka aÃ§Ä±klama yapma.

        KURALLAR:
        - Maksimum 2-3 cÃ¼mle
        - TÃ¼rkÃ§e, samimi ama profesyonel
        - Åikayet varsa Ã§Ã¶zÃ¼m odaklÄ±
        - TeÅŸekkÃ¼r varsa minnettarlÄ±k gÃ¶ster
        - Trendyol satÄ±cÄ±sÄ± kimliÄŸiyle yaz

        CEVAP:
        """)

        self.response_chain = LLMChain(
            llm=self.llm,
            prompt=response_prompt,
            output_key="generated_response",
            output_parser=self.response_parser
        )

        # 3. SEQUENTIAL CHAIN - Ä°ki chain'i sÄ±rayla Ã§alÄ±ÅŸtÄ±r
        self.full_chain = SequentialChain(
            chains=[self.analysis_chain, self.response_chain],
            input_variables=["comment"],
            output_variables=["analysis_result", "generated_response"],
            verbose=True
        )

    def process_single_comment(self, comment: str) -> Dict:
        """Tek yorum iÅŸle"""
        try:
            result = self.full_chain({"comment": comment})

            return {
                "orijinal_yorum": comment,
                "analiz": result["analysis_result"],
                "uretilen_cevap": result["generated_response"]
            }
        except Exception as e:
            return {
                "orijinal_yorum": comment,
                "hata": f"Ä°ÅŸlem hatasÄ±: {str(e)}"
            }

    def process_comments_from_file(self, input_file: str, output_file: str):
        """JSON dosyasÄ±ndan yorumlarÄ± iÅŸle"""

        # Input dosyasÄ±nÄ± oku
        with open(input_file, 'r', encoding='utf-8') as f:
            comments_data = json.load(f)

        all_results = []

        print("ğŸš€ LangChain ile yorum iÅŸleme baÅŸladÄ±...")
        print("-" * 60)

        for i, comment_item in enumerate(comments_data, 1):
            comment_text = comment_item.get('yorum', '')

            print(f"ğŸ“ Ä°ÅŸleniyor ({i}/{len(comments_data)}): {comment_text[:50]}...")

            # Yorumu iÅŸle
            result = self.process_single_comment(comment_text)
            all_results.append(result)

            if 'hata' not in result:
                print(f"âœ… Analiz: {str(result['analiz'])[:100]}...")
                print(f"ğŸ’¬ Cevap: {result['uretilen_cevap']}")
            else:
                print(f"âŒ Hata: {result['hata']}")

            print("-" * 60)

        # Output dosyasÄ±na kaydet
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)

        print(f"âœ… TÃ¼m sonuÃ§lar {output_file} dosyasÄ±na kaydedildi!")
        return all_results


# TOOLS - LangChain Agent iÃ§in (opsiyonel)
def get_response_templates():
    """Cevap ÅŸablonlarÄ±nÄ± dÃ¶ndÃ¼r"""
    templates = {
        "pozitif": ["TeÅŸekkÃ¼rler!", "Memnuniyetiniz gÃ¼zel!"],
        "negatif": ["Ã–zÃ¼r dileriz", "Sorunu Ã§Ã¶zeceÄŸiz"],
        "kargo": ["Kargo gecikmesi iÃ§in Ã¶zÃ¼r dileriz"],
    }
    return str(templates)


# Agent tools tanÄ±mla
tools = [
    Tool(
        name="ResponseTemplates",
        func=get_response_templates,
        description="E-ticaret cevap ÅŸablonlarÄ±nÄ± getir"
    )
]


def run_with_agent_approach(comments_file: str):
    """Agent yaklaÅŸÄ±mÄ± ile Ã§alÄ±ÅŸtÄ±r (alternatif)"""

    llm = ChatAnthropic(
        model="claude-3-7-sonnet-20250219",
        anthropic_api_key=os.getenv("ANTHROPIC_API_KEY")
    )

    memory = ConversationBufferMemory(memory_key="chat_history")

    agent = initialize_agent(
        tools,
        llm,
        agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
        memory=memory,
        verbose=True
    )

    # YorumlarÄ± oku ve agent ile iÅŸle
    with open(comments_file, 'r', encoding='utf-8') as f:
        comments = json.load(f)

    for comment_item in comments:
        comment = comment_item['yorum']

        prompt = f"""
        Bu e-ticaret yorumunu analiz et ve profesyonel cevap Ã¼ret:
        "{comment}"

        1. Ã–nce sentiment ve kategori belirle
        2. Sonra uygun cevap Ã¼ret
        """

        response = agent.run(prompt)
        print(f"Yorum: {comment}")
        print(f"Agent CevabÄ±: {response}")
        print("-" * 80)


def main():
    """Ana fonksiyon"""

    # Dosya yollarÄ±
    input_file = "../../../integrations/ai/agents/agent_comment/data/yorumlar.json"
    output_file = "output/langchain_cevaplar.json"

    # Ä°ÅŸlemci oluÅŸtur
    processor = ECommerceCommentProcessor()

    # YorumlarÄ± iÅŸle
    results = processor.process_comments_from_file(input_file, output_file)

    print(f"\nğŸ‰ Toplam {len(results)} yorum iÅŸlendi!")


if __name__ == "__main__":
    main()